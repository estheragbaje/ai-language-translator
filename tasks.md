# AI Voice Translator â€” Tasks & Process

Target: Realâ€‘time English â†’ French, Spanish, Yoruba, Kinyarwanda. Primary: voice translation; Secondary: text translation. Preferred TTS/STT: ElevenLabs; Translation: choose provider (see Decisions).

## 1) Scope & Goals

- Near realâ€‘time voice â†’ voice translation with minimal latency.
- Reliable text â†’ text translation as a fallback/secondary path.
- Accessible, responsive UI using Next.js + Chakra UI.
- Simple, secure setup and deployment (Vercel-friendly).

## 2) Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ–¥ï¸  CLIENT (Browser)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ¤ Microphone â”€â”€â–º Audio Recorder Hook                                      â”‚
â”‚         â”‚                   â”‚                                               â”‚
â”‚         â”‚                   â”‚ audio chunks                                  â”‚
â”‚         â”‚                   â–¼                                               â”‚
â”‚         â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚         â”‚         â”‚  Chakra UI Display  â”‚â—„â”€â”€â”€ transcripts/translations      â”‚
â”‚         â”‚         â”‚   - Source text     â”‚                                   â”‚
â”‚         â”‚         â”‚   - Translated text â”‚                                   â”‚
â”‚         â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚         â”‚                   â”‚                                               â”‚
â”‚         â”‚                   â”‚ auto-trigger                                  â”‚
â”‚         â”‚                   â–¼                                               â”‚
â”‚         â”‚         ğŸ”Š Audio Player â—„â”€â”€â”€ audio stream                         â”‚
â”‚         â”‚                                                                   â”‚
â”‚  ğŸ“ Text Input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” (secondary path)                            â”‚
â”‚                               â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚ HTTP requests
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      âš¡ NEXT.JS API ROUTES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ /api/stt/stream  â”‚      â”‚ /api/translate   â”‚      â”‚ /api/tts/stream  â”‚  â”‚
â”‚  â”‚ Speech-to-Text   â”‚â”€â”€â”€â”€â”€â–ºâ”‚ Text Translation â”‚â”€â”€â”€â”€â”€â–ºâ”‚ Text-to-Speech   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                         â”‚                         â”‚            â”‚
â”‚           â”‚ audio chunks            â”‚ text (EN)               â”‚ text       â”‚
â”‚           â”‚                         â”‚                         â”‚ (FR/ES/    â”‚
â”‚           â–¼                         â–¼                         â”‚  YO/RW)    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            â”‚
â”‚  â”‚         /api/voice-translate (E2E Pipeline)             â”‚  â”‚            â”‚
â”‚  â”‚         Orchestrates: STT â†’ Translate â†’ TTS             â”‚  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            â”‚
â”‚                                                                â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                 â”‚
                                        HTTP/streaming requests  â”‚
                                                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ğŸŒ EXTERNAL SERVICES                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ElevenLabs STT API â”‚   â”‚   OpenAI API    â”‚   â”‚ ElevenLabs TTS API    â”‚  â”‚
â”‚  â”‚  (audio â†’ text)    â”‚   â”‚  (translation)  â”‚   â”‚ (text â†’ audio)        â”‚  â”‚
â”‚  â”‚                    â”‚   â”‚                 â”‚   â”‚ â€¢ French voices       â”‚  â”‚
â”‚  â”‚  Returns:          â”‚   â”‚  EN â†’ FR/ES/    â”‚   â”‚ â€¢ Spanish voices      â”‚  â”‚
â”‚  â”‚  English text      â”‚   â”‚       YO/RW     â”‚   â”‚ â€¢ Yoruba voices       â”‚  â”‚
â”‚  â”‚                    â”‚   â”‚                 â”‚   â”‚ â€¢ Kinyarwanda voices  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PRIMARY FLOW (Voice Translation):
  ğŸ¤ Mic â†’ Audio Recorder â†’ /api/stt/stream â†’ ElevenLabs STT
                              â†“
                          English Text â†’ Display
                              â†“
                          /api/translate â†’ OpenAI
                              â†“
                      Translated Text (FR/ES/YO/RW) â†’ Display
                              â†“
                          /api/tts/stream â†’ ElevenLabs TTS
                              â†“
                          Audio Stream â†’ Player â†’ ğŸ”Š Speaker

SECONDARY FLOW (Text Translation):
  ğŸ“ Text Input â†’ /api/translate â†’ OpenAI â†’ Display â†’ (optional) â†’ /api/tts/stream
```

### Component Details

- **Client (Next.js App Router + Chakra UI)**
  - Audio capture via Web Audio API (`MediaRecorder` or `AudioWorklet`).
  - Streaming to server for STT; playback streaming audio from TTS.
  - Text input for secondary text translation; transcript display & controls.
- **Server (Next.js API routes / Edge runtime where possible)**
  - STT: ElevenLabs Speech-to-Text (or alternative, see Decisions).
  - Translate: LLM or MT provider (OpenAI/Google/DeepL/NLLB) for ENâ†’FR/ES/YOR/RW.
  - TTS: ElevenLabs multilingual voices; stream back audio to client.
- **Orchestration endpoints (proposed):**
  - `POST /api/stt/stream` â€” streaming STT from mic.
  - `POST /api/translate` â€” translate text payload.
  - `POST /api/tts/stream` â€” streaming TTS for translated text.
  - `POST /api/voice-translate` â€” end-to-end (audioâ†’textâ†’translateâ†’audio) pipeline.

## 3) Key Decisions (choose during Phase 0)

- STT provider:
  - ElevenLabs STT: tight integration with ElevenLabs, good latency.
  - OpenAI Whisper (realtime or batch): high quality, may require relays and higher latency.
- Translation provider:
  - OpenAI (GPT-4o family): strong contextual translation; configurable style/tone.
  - Google Cloud Translate: fast, cost-effective, broad language support.
  - DeepL: strong EU language quality; limited language coverage.
  - Meta NLLB/Marian (hosted): open models; more infra overhead.
- Streaming strategy:
  - True streaming (websocket or chunked POST) vs short chunks (low-latency polling).

## 4) Milestones (Suggested Order)

1. Skeleton app + UI shell
2. Audio capture + basic recording controls
3. STT prototype (short audio â†’ transcript)
4. Translation prototype (text â†’ translated text)
5. TTS prototype (text â†’ audio playback)
6. E2E voiceâ†’voice translation (non-streaming)
7. Streaming path, latency optimizations, VAD/silence handling
8. Settings (languages, voices, style), accessibility
9. QA, observability, deploy

## 5) Detailed Task Checklist

### Phase 0 â€” Project Setup

- [ ] Create `.env.local` with secrets (see Env Vars).
- [ ] Install SDKs/clients for chosen providers.
- [ ] Confirm Chakra UI provider and color mode are configured.
- [ ] Add shared types: language codes, message events, stream frames.

### Phase 1 â€” UI Shell (Next.js + Chakra UI)

- [ ] Add top-level layout: language selectors (source EN, target FR/ES/YOR/RW).
- [ ] Add mic button with states: idle/recording/processing.
- [ ] Add transcript panes: source and translated text.
- [ ] Add text input section for secondary text translation.
- [ ] Add audio player for TTS output; show buffering/streaming state.

### Phase 2 â€” Audio Capture (Client)

- [ ] Implement `useAudioRecorder` (start/stop, errors, permissions).
- [ ] Decide encoding: PCM16/16kHz mono (ideal for STT) or Opus chunks.
- [ ] Optional: client VAD (silence detection) to segment utterances.
- [ ] Stream chunks to `/api/stt/stream` (fetch streaming or websocket fallback).

### Phase 3 â€” STT (Server)

- [ ] Implement `/api/stt/stream` to accept audio chunks.
- [ ] Integrate ElevenLabs STT (or chosen provider) with streaming/partial transcripts.
- [ ] Normalize transcript events; return partial + final results to client.
- [ ] Add error handling, timeouts, size limits.

### Phase 4 â€” Translation (Server)

- [ ] Implement `/api/translate` for text payloads.
- [ ] Provider integration (OpenAI/Google/DeepL/etc.).
- [ ] Support target languages: FR, ES, YO, RW; style knobs (formal/informal).
- [ ] Add glossary/phrase exceptions if needed (names, proper nouns).

### Phase 5 â€” TTS (Server + Client)

- [ ] Implement `/api/tts/stream` with ElevenLabs.
- [ ] Choose voices per target language; expose in UI.
- [ ] Stream audio back; implement client streaming playback.
- [ ] Cache frequent phrases; handle retries.

### Phase 6 â€” E2E Voiceâ†’Voice

- [ ] Implement `/api/voice-translate` orchestrator: STT â†’ Translate â†’ TTS.
- [ ] Non-streaming MVP (batch per utterance), then move to streaming pipeline.
- [ ] Display live source transcript and translated text.
- [ ] Provide download/share of final audio.

### Phase 7 â€” Streaming & Latency

- [ ] Chunk sizes, buffering strategy, and backpressure.
- [ ] VAD thresholds; end-of-utterance detection.
- [ ] Pre-warm TTS voices; reduce synthesis startup time.
- [ ] Parallelize translate + early TTS (speculative) when safe.

### Phase 8 â€” Settings, UX & Accessibility

- [ ] Language dropdown presets and persistence (localStorage).
- [ ] Voice selection per language; preview sample.
- [ ] Text translation mode: paste/enter â†’ translate â†’ play (optional).
- [ ] Keyboard shortcuts; WCAG color contrast; focus states.

### Phase 9 â€” Quality, Testing & Observability

- [ ] Add unit tests for utility functions (formatting, mapping, codecs).
- [ ] Add integration tests for API routes (mocks for providers).
- [ ] Latency telemetry (server timings, client marks), error logging.
- [ ] Phrasebook test set for ENâ†’FR/ES/YO/RW evaluation.

### Phase 10 â€” Deploy

- [ ] Add rate limiting on API routes; request size limits.
- [ ] Configure env on Vercel; validate secrets.
- [ ] Smoke test E2E on production; monitor quotas and costs.
- [ ] Documentation: quick start, privacy notes, limitations.

## 6) Environment Variables

Create `.env.local` (never commit real keys):

```
# ElevenLabs
ELEVENLABS_API_KEY=...
ELEVENLABS_VOICE_ID_FR=...
ELEVENLABS_VOICE_ID_ES=...
ELEVENLABS_VOICE_ID_YO=...
ELEVENLABS_VOICE_ID_RW=...

# If using OpenAI for translation/STT
OPENAI_API_KEY=...

# If using Google Cloud Translate
GOOGLE_PROJECT_ID=...
GOOGLE_CLIENT_EMAIL=...
GOOGLE_PRIVATE_KEY="..."
```

## 7) Dependencies (install as needed)

Use pnpm (already present):

```bash
# ElevenLabs SDK
pnpm add elevenlabs

# If using OpenAI for translation/STT
pnpm add openai

# If using Google Translate (server-side)
pnpm add @google-cloud/translate

# Audio utils (optional)
pnpm add wav-decoder wav-encoder lamejs
```

## 8) API Shapes (Proposed)

- `POST /api/translate`
  - body: `{ text: string, source: 'en', target: 'fr'|'es'|'yo'|'rw', style?: 'formal'|'informal' }`
  - resp: `{ translated: string, provider: string, latencyMs: number }`
- `POST /api/tts/stream`
  - body: `{ text: string, voiceId?: string, language: 'fr'|'es'|'yo'|'rw' }`
  - resp: `audio/mpeg` or chunked stream
- `POST /api/stt/stream`
  - body: `audio/*` chunks
  - resp: server-sent events or NDJSON: `{ type: 'partial'|'final', text: string }`
- `POST /api/voice-translate`
  - body: streaming audio; server returns streaming translated audio

## 9) Testing Plan

- Unit tests for text normalization, language mapping, chunk framing.
- Mock provider SDKs for stable integration tests.
- Latency benchmarks: capture E2E time budget (< 1.5â€“2.5s target).
- Regression suite with phrasebook covering idioms and named entities.

## 10) Risks & Mitigations

- Latency too high â†’ adopt smaller chunks, server locality, pre-warm voices.
- Translation accuracy (YO/RW) â†’ choose provider with best coverage; add glossary.
- Quotas/costs â†’ local caching; truncate long inputs; rate limits.
- Browser permissions/audio device issues â†’ robust error states, retries, help text.

## 11) Next Actions (Day 1)

- [ ] Decide STT + translation providers and record in this file.
- [ ] Implement `useAudioRecorder` and a minimal mic UI.
- [ ] Add `/api/translate` and `/api/tts/stream` basic versions.
- [ ] Hardcode one voice per language and ship a textâ†’audio demo.

---

Maintainer Notes: Keep this file updated as decisions solidify; mark completed tasks and append implementation links (files/PRs).
